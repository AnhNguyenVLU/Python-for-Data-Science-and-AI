{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import stuffs\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"NYCTaxiFares.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.666667\n",
       "1    0.333333\n",
       "Name: fare_class, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#let's check class imbalance of data\n",
    "#the first thing you must do in any dataset\n",
    "df['fare_class'].value_counts(normalize=True)\n",
    "#0 means less than 10 dollars\n",
    "#1 means greater than equal to 10 dollars\n",
    "#upsampling - SMOTE\n",
    "#downsampling - I don't remember\n",
    "#I think there is a library imblearn - take a look\n",
    "#remember, if you use cross-validation, do it during cross-validation\n",
    "#basically, no data leakage........"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def haversine_distance(df, lat1, long1, lat2, long2):\n",
    "    \"\"\"\n",
    "    Calculates the haversine distance between 2 sets of GPS coordinates in df\n",
    "    \"\"\"\n",
    "    r = 6371  # average radius of Earth in kilometers\n",
    "       \n",
    "    phi1 = np.radians(df[lat1])\n",
    "    phi2 = np.radians(df[lat2])\n",
    "    \n",
    "    delta_phi    = np.radians(df[lat2]-df[lat1])\n",
    "    delta_lambda = np.radians(df[long2]-df[long1])\n",
    "     \n",
    "    a = np.sin(delta_phi/2)**2 + np.cos(phi1) * np.cos(phi2) * np.sin(delta_lambda/2)**2\n",
    "    c = 2 * np.arctan2(np.sqrt(a), np.sqrt(1-a))\n",
    "    d = (r * c) # in kilometers\n",
    "\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['pickup_datetime', 'fare_amount', 'fare_class', 'pickup_longitude',\n",
       "       'pickup_latitude', 'dropoff_longitude', 'dropoff_latitude',\n",
       "       'passenger_count'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a column called hav_dis inside df using this function\n",
    "df['hav_dis'] = haversine_distance(df, 'pickup_latitude', \n",
    "                                       'pickup_longitude',\n",
    "                                       'dropoff_latitude', \n",
    "                                       'dropoff_longitude',)\n",
    "\n",
    "#don't put correlated features into the model\n",
    "#all features are assumed to be uncorrelated\n",
    "#ex:  height in inches and height in cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    120000.000000\n",
       "mean          3.322160\n",
       "std           3.337004\n",
       "min           0.010208\n",
       "25%           1.316428\n",
       "50%           2.237084\n",
       "75%           4.034564\n",
       "max          28.846365\n",
       "Name: hav_dis, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['hav_dis'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f41a34f6700>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#a little bit\n",
    "#bivariate analysis between hav_dis and fare_class\n",
    "import seaborn as sns\n",
    "sns.boxplot(x = df.fare_class, y = df.hav_dis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2010-04-19 08:17:56 UTC'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['pickup_datetime'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#what is the time difference between UTC and New York....\n",
    "df['new_york_time'] = pd.to_datetime(df['pickup_datetime'].str[:19]) - pd.Timedelta(hours=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hour  - df['new_york_time'].dt.hour\n",
    "#day   - df['new_york_time'].dt.strftime(\"%a\")\n",
    "#am/pm - np.where(hour < 12, 'am', 'pm')\n",
    "#np.where(condition, if true, if false)\n",
    "df['hour'] = df['new_york_time'].dt.hour\n",
    "df['day']  = df['new_york_time'].dt.strftime(\"%a\")\n",
    "df['ampm'] = np.where(df['hour'] < 12, 'am', 'pm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['am', 'pm'], dtype=object)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['ampm'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#help me write a simple assert function\n",
    "#there should be no more than 24 hours\n",
    "assert len(df['hour'].unique()) <= 24, \"More than 24 hours\"\n",
    "assert df['hour'].min() == 0, \"Some negative hours!\"\n",
    "assert df['hour'].max() == 23, \"Not a normal time system~\"\n",
    "\n",
    "#there should be no more than 7 days\n",
    "assert len(df['day'].unique()) == 7, \"Something not Mon-Sun\"\n",
    "\n",
    "#there should be only am and pm\n",
    "assert (df['ampm'].unique() == np.array(['am', 'pm'])).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#columns name\n",
    "cat_cols  = ['hour', 'ampm', 'day']\n",
    "cont_cols = ['pickup_latitude', 'pickup_longitude', \n",
    "             'dropoff_latitude', 'dropoff_longitude',\n",
    "             'passenger_count', 'hav_dis'] \n",
    "y         = ['fare_class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#there is a dtype called category\n",
    "#which gonna neatly turns our data into integers....\n",
    "#basically it's like label encoding, but much more\n",
    "#why we need to turn it into category first\n",
    "#because, the embedding is like for 0, 1, 2\n",
    "for col in cat_cols:\n",
    "    df[col] = df[col].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['ampm'].cat.categories\n",
    "#df['ampm'].cat.codes\n",
    "#df['ampm'].cat.codes.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pickup_datetime      0\n",
       "fare_amount          0\n",
       "fare_class           0\n",
       "pickup_longitude     0\n",
       "pickup_latitude      0\n",
       "dropoff_longitude    0\n",
       "dropoff_latitude     0\n",
       "passenger_count      0\n",
       "hav_dis              0\n",
       "new_york_time        0\n",
       "hour                 0\n",
       "day                  0\n",
       "ampm                 0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum() #let me guess, no missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120000, 3)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#stack the hours, ampm, and day as one vector\n",
    "\n",
    "hr   = df['hour'].cat.codes.values #[vectors of hours, e.g., 0, 4, 2]\n",
    "ampm = df['ampm'].cat.codes.values\n",
    "day  = df['day'].cat.codes.values\n",
    "\n",
    "time = np.stack([hr, ampm, day], 1)\n",
    "\n",
    "time[:5]\n",
    "\n",
    "time.shape  #(120000 samples, 3 features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 4,  0,  1],\n",
       "        [11,  0,  2],\n",
       "        [ 7,  0,  2]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#convert this numpy into tensor\n",
    "time = torch.tensor(time, dtype=torch.int64)\n",
    "time[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pickup_latitude',\n",
       " 'pickup_longitude',\n",
       " 'dropoff_latitude',\n",
       " 'dropoff_longitude',\n",
       " 'passenger_count',\n",
       " 'hav_dis']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cont_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([120000, 6])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#similarly, we want to stack them into a vector of size 6\n",
    "lat1  = df['pickup_latitude'].values  #.values give you the numpy vector\n",
    "lat2  = df['dropoff_latitude'].values\n",
    "long1 = df['pickup_longitude'].values\n",
    "long2 = df['dropoff_longitude'].values\n",
    "ps_count = df['passenger_count'].values\n",
    "hav_dis  = df['hav_dis'].values\n",
    "#use list comprehension\n",
    "#[df[col].values for col in cont_cols]\n",
    "\n",
    "conts = np.stack([lat1, lat2, long1, long2, ps_count, hav_dis], 1)\n",
    "\n",
    "#turn this into tensor...\n",
    "conts = torch.tensor(conts, dtype=torch.float32)\n",
    "\n",
    "conts[:4]\n",
    "conts.shape  #(120000, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([120000])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#finally, we need the y, to be in tensor\n",
    "y = torch.tensor(df[y].values).flatten()  #reshape(-1)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the size of all my categorical cols\n",
    "cat_size = [len(df[col].cat.categories) for col in cat_cols]\n",
    "#[24, 2, 7]  #[24, 7, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(24, 12), (2, 1), (7, 3)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_size = [(size, min(50, size//2)) for size in cat_size]\n",
    "emb_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 4,  0,  1],\n",
       "        [11,  0,  2]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = time[:1]\n",
    "sample\n",
    "twosamples = time[:2]\n",
    "twosamples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#expected output after embedding of sample\n",
    "#[  [[12 numbers]], [[1 number]], [[3 numbers]]]\n",
    "\n",
    "#expected output after embedding of sample\n",
    "#[  [[12 numbers], [12 numbers]],   [[1 number], [1 number]], \n",
    "#   [[3 numbers], [3 numbers]]    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#emb_size: [(24, 12), (2, 1), (7, 3)]\n",
    "#but pyTorch does not have a list of nn.Embedding\n",
    "#if you want pyTorch to have a list of layers, use nn.ModuleList\n",
    "embed_layer = nn.ModuleList([nn.Embedding(unique, emb_s) for unique, emb_s in emb_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModuleList(\n",
       "  (0): Embedding(24, 12)\n",
       "  (1): Embedding(2, 1)\n",
       "  (2): Embedding(7, 3)\n",
       ")"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#empty embedding\n",
    "sample_embedding = []\n",
    "\n",
    "for i, e in enumerate(embed_layer):\n",
    "    sample_embedding.append(e(twosamples[:, i])) #apply embedding layer to column i\n",
    "                                                 #apply embedding layer 0 to column 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[-0.1945,  0.9901, -1.2819, -2.2350, -1.5727,  1.1993, -1.4804, -0.7679,\n",
       "          -0.1753,  0.2581,  1.0035,  0.9423],\n",
       "         [ 1.5777,  0.1139,  0.1361,  0.5932, -0.9910,  1.4044,  0.5967, -1.8189,\n",
       "          -0.9673,  0.1966, -0.4383,  1.8786]], grad_fn=<EmbeddingBackward0>),\n",
       " tensor([[-0.3774],\n",
       "         [-0.3774]], grad_fn=<EmbeddingBackward0>),\n",
       " tensor([[ 1.5139, -0.6354, -0.0739],\n",
       "         [-0.5574, -0.6597,  0.6562]], grad_fn=<EmbeddingBackward0>)]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1945,  0.9901, -1.2819, -2.2350, -1.5727,  1.1993, -1.4804, -0.7679,\n",
       "         -0.1753,  0.2581,  1.0035,  0.9423, -0.3774,  1.5139, -0.6354, -0.0739],\n",
       "        [ 1.5777,  0.1139,  0.1361,  0.5932, -0.9910,  1.4044,  0.5967, -1.8189,\n",
       "         -0.9673,  0.1966, -0.4383,  1.8786, -0.3774, -0.5574, -0.6597,  0.6562]],\n",
       "       grad_fn=<CatBackward0>)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# in coding, we want to concat all these embeddings, into one vector\n",
    "final_embedding = torch.cat(sample_embedding, 1)\n",
    "\n",
    "final_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gonna teach you very briefly about nn.Dropout\n",
    "#define a dropout layer\n",
    "dl = nn.Dropout(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0000,  0.0000, -0.0000, -0.0000, -3.1454,  2.3987, -2.9609, -1.5359,\n",
       "         -0.0000,  0.5163,  2.0071,  0.0000, -0.0000,  0.0000, -0.0000, -0.1478],\n",
       "        [ 3.1555,  0.2277,  0.2722,  1.1864, -0.0000,  2.8089,  0.0000, -3.6379,\n",
       "         -1.9346,  0.3931, -0.0000,  0.0000, -0.0000, -0.0000, -0.0000,  1.3125]],\n",
       "       grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_embedding = dl(final_embedding)\n",
    "final_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 40.7305,  40.7447, -73.9924, -73.9755,   1.0000,   2.1263],\n",
       "        [ 40.7406,  40.7441, -73.9901, -73.9742,   1.0000,   1.3923]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_cont = conts[:2]\n",
    "sample_cont"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#format: nn.BatchNorm1d(features)\n",
    "batch_norm1d = nn.BatchNorm1d(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.8464,  0.0995, -0.3372, -0.1966,  0.0000,  1.0000],\n",
       "        [ 0.8456, -0.0997,  0.3414,  0.1961,  0.0000, -1.0000]],\n",
       "       grad_fn=<NativeBatchNormBackward0>)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = batch_norm1d(sample_cont)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([120000, 6])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cat_embedding (120000, 16)\n",
    "#cont          (120000, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class someNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, emb_size, cont_size, out_size, layer_size = [200, 100], p=0.5):\n",
    "        super().__init__()\n",
    "        self.embed_layer = nn.ModuleList([nn.Embedding(unique, emb_s) for unique, emb_s in emb_size])\n",
    "        self.dropout     = nn.Dropout(p)\n",
    "        self.batchnorm1d = nn.BatchNorm1d(cont_size)\n",
    "        \n",
    "        #calculate input_size\n",
    "        cat_size = sum(emb_s for _, emb_s in emb_size)\n",
    "        input_size = cat_size + cont_size\n",
    "        \n",
    "        #linear(input_size, 200) -> relu -> batchnorm -> dropout\n",
    "        #linear(200, 100) -> relu -> batchnorm -> dropout\n",
    "        #linear(100, out_size)\n",
    "        layerlist = []\n",
    "        for i in layer_size:\n",
    "            layerlist.append(nn.Linear(input_size, i))  #(input_size, 200)\n",
    "            layerlist.append(nn.ReLU(inplace=True))\n",
    "            layerlist.append(nn.BatchNorm1d(i))\n",
    "            layerlist.append(nn.Dropout(p))\n",
    "            input_size = i\n",
    "        layerlist.append(nn.Linear(layer_size[-1], out_size))\n",
    "        \n",
    "        self.layers = nn.Sequential(*layerlist)\n",
    "            \n",
    "    def forward(self, x_cat, x_cont):\n",
    "        #x_cat:  (120000, 3)\n",
    "        #x_cont: (120000, 6)\n",
    "        embeddings = []\n",
    "        for i, e in enumerate(self.embed_layer):\n",
    "            embeddings.append(e(x_cat[:, i]))\n",
    "        x = torch.cat(embeddings, 1)  \n",
    "        #x: (120000, 16)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x_cont = self.batchnorm1d(x_cont)  \n",
    "        #x_cont: (120000, 6)\n",
    "        \n",
    "        x = torch.cat([x, x_cont], 1)\n",
    "        #x: (120000, 24)\n",
    "        \n",
    "        x = self.layers(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = someNN(emb_size, conts.shape[1], len(y.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's test\n",
    "#random dataset\n",
    "sample_size = 3\n",
    "cat_size    = 3\n",
    "cont_size   = 6\n",
    "\n",
    "p = 0.5\n",
    "x_cat_hour  = torch.randint(0, 24,(sample_size, 1))\n",
    "x_cat_ampm  = torch.randint(0, 2, (sample_size, 1))\n",
    "x_cat_day   = torch.randint(0, 7, (sample_size, 1))\n",
    "x_cat_example      = torch.cat([x_cat_hour, x_cat_ampm, x_cat_day], 1)\n",
    "x_cont_example     = torch.randn(sample_size, cont_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[17,  0,  5],\n",
       "        [20,  0,  5],\n",
       "        [13,  1,  3]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_cat_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.2761, -1.0154, -0.1527, -0.1826,  1.0819, -0.5158],\n",
       "        [-0.2995,  0.1134, -0.2833,  1.7622,  1.4467,  0.1182],\n",
       "        [ 1.1222, -0.3356, -0.4470,  0.1474,  0.2855,  0.6839]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_cont_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model(x_cat_example, x_cont_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0060, -0.5863],\n",
       "        [ 0.5150,  0.3480],\n",
       "        [-0.0858, -0.6645]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define loss function \n",
    "J_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define optimizer (you can try use Adam)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.01)\n",
    "#Adam have dynamic learning schedules....\n",
    "#but it is NOT proven that Adam is better than SGD...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([120000])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#why you not use 120000, too lazy to wait\n",
    "#why you don't use dataloader, because our data is small, only 9 features....\n",
    "\n",
    "#train test split\n",
    "train_size = 60000\n",
    "test_size  = 12000\n",
    "\n",
    "#use your numpy indexing technique\n",
    "cat_train = time[:train_size]\n",
    "cat_test  = time[train_size:test_size+train_size]\n",
    "con_train = conts[:train_size]\n",
    "con_test  = conts[train_size:test_size+train_size]\n",
    "y_train   = y[:train_size]\n",
    "y_test    = y[train_size:test_size+train_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1; Loss: 0.55\n",
      "Epoch: 26; Loss: 0.29\n",
      "Epoch: 51; Loss: 0.27\n",
      "Epoch: 76; Loss: 0.26\n"
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "\n",
    "losses = []\n",
    "\n",
    "for i in range(epochs):\n",
    "    yhat = model(cat_train, con_train)\n",
    "    loss = J_fn(yhat, y_train)\n",
    "    losses.append(loss)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if i % 25 == 1:\n",
    "        print(f\"Epoch: {i}; Loss: {loss:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = [loss.item() for loss in losses]\n",
    "# train_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f41a0a60790>]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(epochs), train_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9113333333333333\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "with torch.no_grad():\n",
    "    yhat = model(cat_test, con_test)\n",
    "    loss = J_fn(yhat, y_test)\n",
    "    predicted = torch.max(yhat, 1)[1]\n",
    "    acc  = accuracy_score(predicted, y_test)\n",
    "    \n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
